# MCQ Questions - Embedding Systems and Vector Databases

## Instructions
Choose the best answer for each question. Each question has only one correct answer.

---

### Question 1
What are embeddings in the context of machine learning?

A) A method for compressing images  
B) High-dimensional numerical representations of data that capture semantic meaning  
C) A type of database index  
D) A programming language feature  

**Answer: B**

---

### Question 2
What is the primary purpose of a vector database?

A) To store traditional relational data  
B) To efficiently store and search high-dimensional vectors for similarity matching  
C) To compress text files  
D) To manage user authentication  

**Answer: B**

---

### Question 3
Which distance metric is commonly used for measuring similarity between embeddings?

A) Manhattan distance only  
B) Cosine similarity and Euclidean distance  
C) Hamming distance  
D) Edit distance  

**Answer: B**

---

### Question 4
What does FAISS stand for in the context of vector databases?

A) Fast Artificial Intelligence Search System  
B) Facebook AI Similarity Search  
C) Flexible Array Indexing Storage System  
D) Functional AI Search Service  

**Answer: B**

---

### Question 5
What is the main advantage of using pre-trained embedding models?

A) They are always free to use  
B) They capture general semantic understanding without requiring custom training  
C) They work only with English text  
D) They are smaller in size than custom models  

**Answer: B**

---

### Question 6
In semantic search, what is the key difference from traditional keyword search?

A) Semantic search is always faster  
B) Semantic search finds results based on meaning and context, not just exact word matches  
C) Semantic search only works with numbers  
D) Semantic search requires less computational power  

**Answer: B**

---

### Question 7
What is the typical dimensionality range for modern text embeddings?

A) 10-50 dimensions  
B) 100-200 dimensions  
C) 256-4096 dimensions  
D) 10,000+ dimensions  

**Answer: C**

---

### Question 8
What is the purpose of "indexing" in vector databases?

A) To sort data alphabetically  
B) To create data structures that enable fast similarity search across large collections  
C) To compress the vectors  
D) To encrypt the data  

**Answer: B**

---

### Question 9
Which of the following is NOT a common application of embedding systems?

A) Semantic search  
B) Recommendation systems  
C) Traditional SQL queries  
D) Document clustering  

**Answer: C**

---

### Question 10
What does "k" represent in k-nearest neighbors search for embeddings?

A) The number of dimensions in the embedding  
B) The number of similar items to return  
C) The number of databases to search  
D) The number of API calls to make  

**Answer: B**

---

### Question 11
What is a key consideration when choosing embedding dimensions?

A) Higher dimensions always mean better performance  
B) Balance between expressiveness and computational/storage efficiency  
C) Dimensions should always be powers of 2  
D) Dimensions don't affect performance  

**Answer: B**

---

### Question 12
What is the purpose of "persistence" in embedding systems?

A) To make the system run continuously  
B) To save embeddings and indices to disk for reuse across sessions  
C) To increase processing speed  
D) To reduce memory usage  

**Answer: B**

---

### Question 13
In the context of embeddings, what does "semantic similarity" mean?

A) Texts that look visually similar  
B) Texts that have similar meaning or context, even if they use different words  
C) Texts that have the same length  
D) Texts written by the same author  

**Answer: B**

---

### Question 14
What is a common challenge when working with large-scale embedding systems?

A) Embeddings are too small to be useful  
B) Managing computational and storage requirements for high-dimensional data  
C) Embeddings only work with small datasets  
D) Vector databases are not scalable  

**Answer: B**

---

### Question 15
What is the benefit of using approximate nearest neighbor (ANN) algorithms in vector search?

A) They provide exact results every time  
B) They trade slight accuracy for significant speed improvements in large-scale searches  
C) They use less memory than exact search  
D) They work only with small datasets  

**Answer: B**

---

## Answer Key Summary
1. B  2. B  3. B  4. B  5. B  
6. B  7. C  8. B  9. C  10. B  
11. B  12. B  13. B  14. B  15. B

---

**Total Questions: 15**  
**Topics Covered:** Embeddings, Vector Databases, Semantic Search, FAISS, Similarity Metrics, Indexing, Dimensionality, and System Architecture